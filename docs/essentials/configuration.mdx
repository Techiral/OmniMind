---
title: "Configuration"
description: "Configure your OmniMind environment"
---

# Configuration Guide

This guide covers all the configuration options available in OmniMind.

## API Keys

Make sure to have the api key relative to the provider of your choice available in the environment. You can either:

1 - Create `.env` file with your keys as:

```bash
# OpenAI
OPENAI_API_KEY=your_api_key_here
# Anthropic
ANTHROPIC_API_KEY=your_api_key_here
# Groq
GROQ_API_KEY=your_api_key_here
# Gemini
GEMINI_API_KEY=your_api_key_here
```

and load it in Python using

```python
from dotenv import load_dotenv
load_dotenv()
```

This will make all the keys defined in `.env` available in your Python runtime, granted that you run from where the .env is located.

2 - Set it in your environment by running in your terminal the following command, e.g., for OpenAI:

```bash
export OPENAI_API_KEY='..."
```

and then import it in your Python code as:

```python
import os
OPENAI_API_KEY = os.getenv(OPENAI_API_KEY,"")
```

or any other method you might prefer.

## MCP Server Configuration

mcp_use supports any MCP server through a flexible configuration system. (For a list of awesome servers, you can visit https://github.com/punkpeye/awesome-mcp-servers or https://github.com/appcypher/awesome-mcp-servers, which have an amazing collection of them)

The configuration is defined in a JSON file with the following structure:

```json
{
  "mcpServers": {
    "server_name": {
      "command": "command_to_run",
      "args": ["arg1", "arg2"],
      "env": {
        "ENV_VAR": "value"
      }
    }
  }
}
```

MCP servers can use different connection types (STDIO, HTTP). For details on these connection types and how to configure them, see the [Connection Types](./connection-types) guide.

### Configuration Options

- `server_name`: A unique identifier for your MCP server
- `command`: The command to start the MCP server
- `args`: Array of arguments to pass to the command
- `env`: Environment variables to set for the server

### Example Configuration

Here's a basic example of how to configure an MCP server:

```json
{
  "mcpServers": {
    "my_server": {
      "command": "npx",
      "args": ["@my-mcp/server"],
      "env": {
        "PORT": "3000"
      }
    }
  }
}
```

### Multiple Server Configuration

You can configure multiple MCP servers in a single configuration file, allowing you to use different servers for different tasks or combine their capabilities (e.g.):

```json
{
  "mcpServers": {
    "airbnb": {
      "command": "npx",
      "args": ["-y", "@openbnb/mcp-server-airbnb", "--ignore-robots-txt"]
    },
    "playwright": {
      "command": "npx",
      "args": ["@playwright/mcp@latest"],
      "env": { "DISPLAY": ":1" }
    },
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/home/pietro/projects/mcp-use/"]
    }
  }
}
```

For a complete example of using multiple servers, see the [multi-server example](https://github.com/pietrozullo/mcp-use/blob/main/examples/multi_server_example.py) in our repository.

## Agent Configuration

When creating an MCPAgent, you can configure several parameters:

```python
from omnimind import OmniMind
import asyncio
import os
import json

async def advanced_multi_server_usage():
    # Ensure GOOGLE_API_KEY is set
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("Please set the GOOGLE_API_KEY environment variable before running this script")

    # Initialize OmniMind with the multi-server config
    agent = OmniMind(config_path="multi_server_config.json", api_key=api_key)
    try:
        # Connect to all servers
        await agent._connect_servers()
        print("Tools loaded:", [tool.name for tool in agent.tools])

        # Step 1: Fetch web content
        fetch_query = "Fetch the content of 'https://marvel.fandom.com/wiki/Stark_Industries_(Earth-616)' and summarize it"
        fetch_response = await agent.invoke(fetch_query)
        summary = fetch_response["messages"][-1].content  # Extract the summary from the last message
        print("\nStep 1 - Web Summary:", summary)

        # Step 2: Store the summary in memory
        memory_query = f"Store this in memory under key 'stark_summary': {summary}"
        await agent.invoke(memory_query)
        print("Step 2 - Stored summary in memory")

        # Step 3: Recall from memory and save to a file
        recall_query = "Recall the value stored under 'stark_summary' and save it to a file named 'stark_summary.txt' in the workspace directory"
        recall_response = await agent.invoke(recall_query)
        print("Step 3 - Recalled and saved to file:", recall_response["messages"][-1].content)

    except Exception as e:
        print(f"Error during execution: {e}")
    finally:
        await agent.close()

if __name__ == "__main__":
    asyncio.run(advanced_multi_server_usage())
```

### Available Parameters

- `config_path`: Path to the server configuration file.
- `api_key`: Authentication key for accessing services.
- `server_name`: Specifies the target server for tasks.

## Error Handling

mcp_use provides several ways to handle errors:

1. **Connection Errors**: Check your MCP server configuration and ensure the server is running
2. **Authentication Errors**: Verify your API keys are correctly set in the environment
3. **Timeout Errors**: Adjust the `max_steps` parameter if operations are timing out

## Best Practices

1. Always use environment variables for sensitive information
2. Keep configuration files in version control (without sensitive data)
3. Use appropriate timeouts for different types of operations
4. Enable verbose logging during development
5. Test configurations in a development environment before production