---
title: "Quickstart"
description: "Get started with OmniMind in minutes!"
---

# Quickstart Guide

This guide will help you get started with OmniMind quickly. We'll cover installation, basic configuration, and running your first agent.

## Installation

You can install OmniMind using pip:

```bash
pip install omnimind
```

Or install from source:

```bash
git clone https://github.com/Techiral/OmniMind.git
cd OmniMind
pip install -e .
```

## Installing LangChain Providers

OmniMind works with various LLM providers through LangChain. You'll need to install the appropriate LangChain provider package for your chosen LLM. For example:

```bash
# For OpenAI
pip install langchain-openai

# For Anthropic
pip install langchain-anthropic

# For other providers, check the [LangChain chat models documentation](https://python.langchain.com/docs/integrations/chat/)
```

> **Important**: Only models with tool calling capabilities can be used with OmniMind. Make sure your chosen model supports function calling or tool use.

## Environment Setup

Set up your environment variables in a `.env` file:

```bash
OPENAI_API_KEY=your_api_key_here
ANTHROPIC_API_KEY=your_api_key_here
```

## Your First Agent

Here's a simple example to get you started:

```python
# Add your own server to OmniMind
from omnimind import OmniMind

agent = OmniMind()
agent.add_server("my_server", command="python", args=["my_server.py"])
agent.run()  # Your serverâ€™s live!
```

## Configuration Options

You can also add the servers configuration from a config file:

```python
# Initialize OmniMind with the multi-server config
agent = OmniMind(config_path="browser_mcp.json", api_key=api_key)
```

Example configuration file (`browser_mcp.json`):

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": ["@playwright/mcp@latest"],
      "env": {
        "DISPLAY": ":1"
      }
    }
  }
}
```

## Using Multiple Servers

The `MCPClient` can be configured with multiple MCP servers, allowing your agent to access tools from different sources. This capability enables complex workflows spanning various domains (e.g., web browsing and API interaction).

**Configuration:**

Define multiple servers in your configuration file (`multi_server_config.json`):

```json
{
    "mcpServers": {
        "fetch": {
            "command": "uvx",
            "args": ["mcp-server-fetch"]
        },
        "memory": {
            "command": "C:\\Program Files\\nodejs\\npx.cmd",
            "args": [
                "-y",
                "@modelcontextprotocol/server-memory"
            ],
            "env": {
                "MEMORY_FILE_PATH": "C:\\Users\\Lenovo\\OneDrive\\Desktop\\final JARVIS\\mcp\\workspace\\memory.json"
            }
        },
        "filesystem": {
            "command": "C:\\Program Files\\nodejs\\npx.cmd",
            "args": [
                "-y",
                "@modelcontextprotocol/server-filesystem",
                "C:\\Users\\Lenovo\\OneDrive\\Desktop",
                "C:\\Users\\Lenovo\\OneDrive\\Desktop\\final JARVIS\\mcp\\workspace"
            ]
        }
    }
}
```

**Usage:**

When working with an `OmniMind` agent is configured for multiple servers, the agent can access tools available on all the connected servers. However, for tasks targeting a specific server, you may need to explicitly specify which server to use. This is done using the `server_name` parameter in the `agent.run()` method, as demonstrated in the following code snippet:

```python
# Initialize OmniMind with the multi-server config
agent = OmniMind(config_path="multi_server_config.json", api_key=api_key)
try:
    # Connect to all servers
    await agent._connect_servers()
    print("Tools loaded:", [tool.name for tool in agent.tools])

    # Step 1: Fetch web content
    fetch_query = "Fetch the content of 'https://marvel.fandom.com/wiki/Stark_Industries_(Earth-616)' and summarize it"
    fetch_response = await agent.invoke(fetch_query)
    summary = fetch_response["messages"][-1].content  # Extract the summary from the last message
    print("\nStep 1 - Web Summary:", summary)
except Exception as e:
    print(f"Error during execution: {e}")
finally:
     await agent.close()
```

## Available MCP Servers

OmniMind supports any MCP server, allowing you to connect to a wide range of server implementations. For a comprehensive list of available servers, check out the [awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers) repository.

Each server requires its own configuration. Check the [Configuration Guide](/essentials/configuration) for details.

## Next Steps

- Learn about [Configuration Options](/essentials/configuration)
- Explore [Example Use Cases](/examples)
- Check out [Advanced Features](/essentials/advanced)