Ok, Solve my all errors:

File Tree-
omnimind/
    __init__.py
    client.py
    config.py
    MANIFEST.in
    utils.py
setup.py
pyproject.toml

__init__.py:
`"""OmniMind: A plug-and-play Python library for MCP server integration with Google Gemini."""

from .client import OmniMind

__version__ = "0.1.0"
__all__ = ["OmniMind"]`

client.py:
`# client.py

# ─────────────────────────────────────────────────────────────────────────────
# Suppress Windows asyncio “unclosed transport” ResourceWarning at shutdown
# ─────────────────────────────────────────────────────────────────────────────
import warnings
warnings.filterwarnings("ignore", category=ResourceWarning, message="unclosed transport.*")

import asyncio
import os
import logging
import signal
import sys
import atexit
from contextlib import AsyncExitStack, suppress
import json
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from .config import load_config
from .utils import CustomEncoder

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

_active_instances = set()

class OmniMind:
    def __init__(self, config_path, api_key=None):
        self.config = load_config(config_path)
        google_api_key = api_key or os.getenv("GOOGLE_API_KEY")
        if not google_api_key:
            raise ValueError("GOOGLE_API_KEY must be provided via env or api_key")
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0,
            max_retries=2,
            google_api_key=google_api_key
        )
        self.tools = []
        self.agent = None
        self.sessions = {}
        self.exit_stack = None
        self.is_connected = False
        self._transports = []

        _active_instances.add(self)
        for sig in (signal.SIGINT, signal.SIGTERM):
            signal.signal(sig, lambda *_: self._emergency_cleanup())
        atexit.register(self._ensure_cleanup)

    def _emergency_cleanup(self):
        if self.is_connected:
            logger.warning("Emergency cleanup…")
            try:
                loop = asyncio.new_event_loop()
                loop.run_until_complete(self.close())
                loop.close()
            except Exception as e:
                logger.error(f"Error during emergency cleanup: {e}")
        _active_instances.discard(self)

    def _ensure_cleanup(self):
        if self.is_connected:
            logger.warning("Exit cleanup…")
            try:
                loop = asyncio.new_event_loop()
                loop.run_until_complete(self.close())
                loop.close()
            except Exception as e:
                logger.error(f"Error during cleanup: {e}")
        _active_instances.discard(self)

    async def _connect_servers(self):
        if self.is_connected:
            return

        servers = self.config.get("mcpServers", {})
        if not servers:
            raise ValueError("No MCP servers in config")

        self.exit_stack = AsyncExitStack()
        
        try:
            for name, info in servers.items():
                logger.info(f"Connecting: {name}")

                env = os.environ.copy()
                env.update(info.get("env", {}))

                params = StdioServerParameters(
                    command=info["command"],
                    args=info["args"],
                    env=env
                )

                try:
                    read, write = await self.exit_stack.enter_async_context(
                        stdio_client(params)
                    )
                    for stream in (read, write):
                        tr = getattr(stream, "_transport", None)
                        if tr:
                            self._transports.append(tr)
                            proc = getattr(tr, "_proc", None)
                            if proc:
                                self._transports.append(proc)

                    session = await self.exit_stack.enter_async_context(
                        ClientSession(read, write)
                    )
                    await session.initialize()
                    logger.info(f"{name} initialized")

                    tools = await load_mcp_tools(session)
                    if tools:
                        self.tools.extend(tools)
                        logger.info(f"{len(tools)} tools from {name}")
                    else:
                        logger.warning(f"No tools on {name}")

                    self.sessions[name] = session

                except Exception as e:
                    logger.error(f"{name} failed: {e}")

            if not self.tools:
                raise RuntimeError("No tools loaded")

            self.agent = create_react_agent(self.llm, self.tools)
            self.is_connected = True
            logger.info(f"Agent ready with: {self.format_tools(self.tools)}")

        except Exception:
            await self.exit_stack.aclose()
            raise

    async def close(self):
        if not self.is_connected:
            return

        logger.info("Closing connections…")
        self.sessions.clear()
        self.tools.clear()
        self.agent = None

        if self.exit_stack:
            with suppress(Exception):
                await self.exit_stack.aclose()
            self.exit_stack = None

        for obj in self._transports:
            with suppress(Exception):
                if hasattr(obj, "terminate"):
                    obj.terminate()
                if hasattr(obj, "close"):
                    obj.close()
        self._transports.clear()

        self.is_connected = False
        logger.info("All cleaned up")

    async def invoke(self, query: str):
        if not self.is_connected:
            await self._connect_servers()
        return await self.agent.ainvoke({"messages": [HumanMessage(content=query)]})

    async def __aenter__(self):
        await self._connect_servers()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        await self.close()

    def format_tools(self, tools):
        return "\n".join([f"'{tool.name}'" for tool in tools])

    def run(self):
        async def _loop():
            await self._connect_servers()
            print("Ready! Type 'quit' to exit.")
            while True:
                q = input("Query: ").strip()
                if q.lower() == "quit":
                    break
                resp = await self.agent.ainvoke({"messages": [HumanMessage(content=q)]})
                print(json.dumps(resp, indent=2, cls=CustomEncoder))
            await self.close()

        try:
            asyncio.run(_loop())
        except KeyboardInterrupt:
            asyncio.run(self.close())
        except Exception as e:
            logger.error(f"Error during run: {e}")`

config.py:
`import os
import json

def load_config(config_path):
    """Load MCP server config from a user-provided file."""
    if not config_path:
        raise ValueError("A config file path must be provided to use OmniMind")
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Config file not found at '{config_path}'")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        if not config.get("mcpServers"):
            raise ValueError("Config file must contain 'mcpServers' key with server definitions")
        return config
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON in config file at '{config_path}': {e}")
    except Exception as e:
        raise FileNotFoundError(f"Failed to load config at '{config_path}': {e}")`

MANIFEST.in:
`include README.md
include LICENSE
include pyproject.toml`

utils.py:
`import json

class CustomEncoder(json.JSONEncoder):
    def default(self, o):
        if hasattr(o, "content"):
            return {"type": o.__class__.__name__, "content": o.content}
        return super().default(o)`

setup.py:
`from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="omnimind",
    version="0.1.0",
    author="Lakshya Gupta",
    author_email="techiralthefuture@gmail.com",
    description="A plug-and-play Python library for effortless MCP server integration, powered by Google Gemini",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/Techiral/OmniMind",
    license="MIT",
    packages=find_packages(exclude=["testenv", "tests", "*.egg-info"]),
    install_requires=[
        "mcp>=1.6.0",
        "langchain-google-genai>=2.1.2",
        "langgraph>=0.3.25",
        "langchain-mcp-adapters>=0.0.7",
        "python-dotenv>=1.1.0",
    ],
    classifiers=[
        "Programming Language :: Python :: 3",
        "Operating System :: OS Independent",
        "Topic :: Software Development :: Libraries :: Python Modules",
        "Intended Audience :: Developers",
        "Development Status :: 3 - Alpha",
    ],
    python_requires=">=3.8",
)
`

The output (error):
`Remove-Item build,dist,*.egg-info -Recurse -Force -ErrorAction SilentlyContinue
>> python -m build
>> twine check dist/*
>> twine upload --repository testpypi dist/*
>>
* Creating isolated environment: venv+pip...
* Installing packages in isolated environment:
  - setuptools >= 40.8.0
* Getting build dependencies for sdist...
running egg_info
creating omnimind.egg-info        
writing omnimind.egg-info\PKG-INFO
writing dependency_links to omnimind.egg-info\dependency_links.txt
writing requirements to omnimind.egg-info\requires.txt
writing top-level names to omnimind.egg-info\top_level.txt
writing manifest file 'omnimind.egg-info\SOURCES.txt'
reading manifest file 'omnimind.egg-info\SOURCES.txt'
adding license file 'LICENSE'
writing manifest file 'omnimind.egg-info\SOURCES.txt'
* Building sdist...
running sdist
running egg_info
writing omnimind.egg-info\PKG-INFO
writing dependency_links to omnimind.egg-info\dependency_links.txt
writing requirements to omnimind.egg-info\requires.txt
writing top-level names to omnimind.egg-info\top_level.txt
reading manifest file 'omnimind.egg-info\SOURCES.txt'
adding license file 'LICENSE'
writing manifest file 'omnimind.egg-info\SOURCES.txt'
running check
creating omnimind-0.1.0
creating omnimind-0.1.0\omnimind
creating omnimind-0.1.0\omnimind.egg-info
creating omnimind-0.1.0\tests
copying files to omnimind-0.1.0...
copying LICENSE -> omnimind-0.1.0
copying README.md -> omnimind-0.1.0
copying setup.py -> omnimind-0.1.0
copying omnimind\__init__.py -> omnimind-0.1.0\omnimind
copying omnimind\client.py -> omnimind-0.1.0\omnimind
copying omnimind\config.py -> omnimind-0.1.0\omnimind
copying omnimind\utils.py -> omnimind-0.1.0\omnimind
copying omnimind.egg-info\PKG-INFO -> omnimind-0.1.0\omnimind.egg-info
copying omnimind.egg-info\SOURCES.txt -> omnimind-0.1.0\omnimind.egg-info
copying omnimind.egg-info\dependency_links.txt -> omnimind-0.1.0\omnimind.egg-info
copying omnimind.egg-info\requires.txt -> omnimind-0.1.0\omnimind.egg-info
copying omnimind.egg-info\top_level.txt -> omnimind-0.1.0\omnimind.egg-info
copying tests\test_client.py -> omnimind-0.1.0\tests
copying tests\test_config.py -> omnimind-0.1.0\tests
copying omnimind.egg-info\SOURCES.txt -> omnimind-0.1.0\omnimind.egg-info
Writing omnimind-0.1.0\setup.cfg
Creating tar archive
removing 'omnimind-0.1.0' (and everything under it)
* Building wheel from sdist
* Creating isolated environment: venv+pip...
* Installing packages in isolated environment:
  - setuptools >= 40.8.0
* Getting build dependencies for wheel...
running egg_info
writing omnimind.egg-info\PKG-INFO
writing dependency_links to omnimind.egg-info\dependency_links.txt
writing requirements to omnimind.egg-info\requires.txt
writing top-level names to omnimind.egg-info\top_level.txt
reading manifest file 'omnimind.egg-info\SOURCES.txt'
adding license file 'LICENSE'
writing manifest file 'omnimind.egg-info\SOURCES.txt'
* Building wheel...
running bdist_wheel
running build
running build_py
creating build\lib\omnimind
copying omnimind\client.py -> build\lib\omnimind
copying omnimind\config.py -> build\lib\omnimind
copying omnimind\utils.py -> build\lib\omnimind
copying omnimind\__init__.py -> build\lib\omnimind
installing to build\bdist.win-amd64\wheel
running install
running install_lib
creating build\bdist.win-amd64\wheel
creating build\bdist.win-amd64\wheel\omnimind
copying build\lib\omnimind\client.py -> build\bdist.win-amd64\wheel\.\omnimind
copying build\lib\omnimind\config.py -> build\bdist.win-amd64\wheel\.\omnimind
copying build\lib\omnimind\utils.py -> build\bdist.win-amd64\wheel\.\omnimind
copying build\lib\omnimind\__init__.py -> build\bdist.win-amd64\wheel\.\omnimind
running install_egg_info
running egg_info
writing omnimind.egg-info\PKG-INFO
writing dependency_links to omnimind.egg-info\dependency_links.txt
writing requirements to omnimind.egg-info\requires.txt
writing top-level names to omnimind.egg-info\top_level.txt
reading manifest file 'omnimind.egg-info\SOURCES.txt'
adding license file 'LICENSE'
writing manifest file 'omnimind.egg-info\SOURCES.txt'
Copying omnimind.egg-info to build\bdist.win-amd64\wheel\.\omnimind-0.1.0-py3.12.egg-info
running install_scripts
creating build\bdist.win-amd64\wheel\omnimind-0.1.0.dist-info\WHEEL
creating 'C:\Users\Lenovo\OneDrive\Desktop\final JARVIS\OmniMind\dist\.tmp-j4z9e9i7\omnimind-0.1.0-py3-none-any.whl' and adding 'build\bdist.win-amd64\wheel' to it
adding 'omnimind/__init__.py'
adding 'omnimind/client.py'
adding 'omnimind/config.py'
adding 'omnimind/utils.py'
adding 'omnimind-0.1.0.dist-info/licenses/LICENSE'
adding 'omnimind-0.1.0.dist-info/METADATA'
adding 'omnimind-0.1.0.dist-info/WHEEL'
adding 'omnimind-0.1.0.dist-info/top_level.txt'
adding 'omnimind-0.1.0.dist-info/RECORD'
removing build\bdist.win-amd64\wheel
Successfully built omnimind-0.1.0.tar.gz and omnimind-0.1.0-py3-none-any.whl
Checking dist\omnimind-0.1.0-py3-none-any.whl: ERROR    InvalidDistribution: Metadata is missing required fields: Name, Version.
         Make sure the distribution includes the files where those fields are specified, and is using a supported  
         Metadata-Version: 1.0, 1.1, 1.2, 2.0, 2.1, 2.2, 2.3.
Uploading distributions to https://test.pypi.org/legacy/
ERROR    InvalidDistribution: Metadata is missing required fields: Name, Version.
         Make sure the distribution includes the files where those fields are specified, and is using a supported  
         Metadata-Version: 1.0, 1.1, 1.2, 2.0, 2.1, 2.2, 2.3.
PS C:\Users\Lenovo\OneDrive\Desktop\final JARVIS\OmniMind> `